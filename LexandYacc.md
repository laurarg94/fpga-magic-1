# Introduction #

The Magic-1 assembly was written in C using Lex and Yacc tools. This page will be a small tutorial based on this [tutorial](http://www.scribd.com/doc/8669782/Lex-Yacc-Tutorialshort)


![http://i219.photobucket.com/albums/cc244/leonardoaraujo/Parser_Flow.gif](http://i219.photobucket.com/albums/cc244/leonardoaraujo/Parser_Flow.gif)


# Details #

## Lex ##
First we will begin with Lex, Lex generates a C function called **Lexer** wich receives a stream of characters and recognizes some group of characters called [tokens](http://pt.wikipedia.org/wiki/Token) and do some action. This is also called lexical [analysis](http://en.wikipedia.org/wiki/Lexical_analysis)

For example this file will generate a program that wait the tokens **start** and **stop** and do some action, otherwise will just echo what was typed.

```
/* Definition part */
%{
#include <stdio.h>
%}

/* Rules */
%%
stop printf("Stop command received\n");
start printf("Start command received\n");
%%

/* Code */
```

For compile it:

```
lex example1.l
cc lex.yy.c -o example1 -ll
```
![http://i219.photobucket.com/albums/cc244/leonardoaraujo/Tela_Lex.jpg](http://i219.photobucket.com/albums/cc244/leonardoaraujo/Tela_Lex.jpg)

Anything between {% and %} will be copied to the output C file, sections will be separated with %% , the Rules part will be used to define the token rules as [regular expressions](http://en.wikipedia.org/wiki/Regular_expression). The code section will be used to define the **main** routine if you leave it empty and compile it with -ll the default main will be created, otherwise the yacc code will be used.

The other example will use a regular expression to define some token:

```
/* Definition part */
%{
#include <stdio.h>
%}

/* Rules */
%%
[0-9]+   printf("NUMBER\n");
[a-zA-Z][a-zA-Z0-9]*   printf("WORD\n");
%%

/* Code */
```

For compile it:

```
lex example2.l
cc lex.yy.c -o example1 -ll
```

The Rules part defines 2 tokens **NUMBER** and **WORD**
  * **NUMBER:** Defines a sequence of 1 or more characters from 0 to 9
  * **WORD:** In the first part matches 1 and only 1 character from a to z or A to Z then the second part could be zero or more characters from a to z or A to Z or 0 to 9

This way, we’ve mimicked the behaviour of many programming languages which demand that a variable name **must** start with a letter, but can contain digits afterwards. In other words, **’temperature1’** is a valid name, but **’1temperature’** is not.

Now we're going to define a **tokenizer** for reading a file that looks like this...

```
logging {
category lame-servers { null; };
category cname { null; };
};
zone "." {
type hint;
file "/etc/bind/db.root";
};
```

Just analysing this file we can see the following tokens
  * WORDs, like ’zone’ and ’type’
  * FILENAMEs, like ’/etc/bind/db.root’
  * QUOTEs, like those surrounding the filename
  * OBRACEs, {
  * EBRACEs, }
  * SEMICOLONs, ;

The lex file for **tokenizing** this file will be:

```
/* Definition part */
%{
#include <stdio.h>
%}

/* Rules */
%%
[a-zA-Z][a-zA-Z0-9]* printf("WORD ");
[a-zA-Z0-9\/.-]+ printf("FILENAME ");
\" printf("QUOTE ");
\{ printf("OBRACE ");
\} printf("EBRACE ");
; printf("SEMICOLON ");
\n printf("\n");
[ \t]+ /* ignore whitespace */;
%%

/* Code */
```

The output of this tokenizer will be:

```
WORD OBRACE
WORD FILENAME OBRACE WORD SEMICOLON EBRACE SEMICOLON
WORD WORD OBRACE WORD SEMICOLON EBRACE SEMICOLON
EBRACE SEMICOLON
WORD QUOTE FILENAME QUOTE OBRACE
WORD WORD SEMICOLON
WORD QUOTE FILENAME QUOTE SEMICOLON
EBRACE SEMICOLON
```

We’ve seen that Lex is able to read arbitrary input, and determine what each part of the input is. This is called ’Tokenizing’.
Now those tokens will be the input for **YACC**

## YACC ##
YACC can [parse](http://en.wikipedia.org/wiki/Parsing) input streams consisting of tokens witch certain values. The parsing is the process of interpreting the tokens following the rules of a specific language(grammar), and taking some action.

We're going to control a thermostat that follows a simple language....
The tokens we need to recognize are: heat, on/off (STATE), target, temperature, NUMBER.

```
heat on
Heater on!
heat off
Heater off!
target temperature 22
New temperature set!
```

The LEX input source to tokenize this :


```
%{
#include <stdio.h>
#include "y.tab.h"
%}

%%
[0-9]+ return NUMBER;
heat return TOKHEAT;
on|off return STATE;
target return TOKTARGET;
temperature return TOKTEMPERATURE;
\n /* ignore end of line */;
[ \t]+ /* ignore whitespace */;
%%
```

We can observe that we don't printf things anymore, now we return values that will be send to YACC. Other point we include the file **y.tab.h** wich will define those tokens values. This file is autogenerated from YACC grammar file.

```
%{
#include <stdio.h>
#include <string.h>

void yyerror(const char *str)
{
	fprintf(stderr,"error: %s\n",str);
}

int yywrap()
{
	return 1;
}

main()
{
	yyparse();
}

%}

%token NUMBER TOKHEAT STATE TOKTARGET TOKTEMPERATURE

%%

/* Grammar  */

commands: /* empty */
	| commands command
	;


command:
	heat_switch
	|
	target_set
	;

heat_switch:
	TOKHEAT STATE 
	{
		printf("\tHeat turned on or off\n");
	}
	;

target_set:
	TOKTARGET TOKTEMPERATURE NUMBER
	{
		printf("\tTemperature set\n");
	}
	;
```

### Header explanation ###

The header part defines the token names and also some routines
  * yyerror() - This routine is called by YACC uppon some error. We simply output the message passed but there are other smarter things to do.
  * yywrap() - This routint is used if you want to read from another file is called when EOF is reached, when you can open another file and return 0, or else you can return 1 to indicate that is over.
  * main() - This routine sets everything in motion.
  * token - This part defines all the tokens used NUMBER TOKHEAT STATE TOKTARGET TOKTEMPERATURE, those will be output if you use '-d' option of YACC.

### Gramar explanation ###
The first part is what I call the ’root’. It tells us that we have ’commands’, and that these commands consist of individual ’command’ parts. As you can see this rule is very recursive, because it again contains the word ’commands’. What this means is that the program is now capable of reducing a series of commands one by one. The second rule defines what a command is. We support only two kinds of commands, the ’heat switch’ and the ’target set’. This is what the j-symbol signifies - ’a command consists of either a heat switch or a target set’. A heat switch consists of the HEAT token, which is simply the word ’heat’, followed by a state (which we defined in the Lex file as ’on’ or ’off’). Somewhat more complicated is the target set, which consists of the TARGET token (the word ’target’), the TEMPERATURE token (the word ’temperature’) and a number.

### Compiling ###
In order to compile the example above...

```
lex example4.l
yacc -d example4.y
cc lex.yy.c y.tab.c -o example4
```