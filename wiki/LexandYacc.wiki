#summary Lex and Yacc tutorial.
#labels Featured,Phase-Implementation

= Introduction =

The Magic-1 assembly was written in C using Lex and Yacc tools. This page will be a small tutorial based on this [http://www.scribd.com/doc/8669782/Lex-Yacc-Tutorialshort tutorial]


= Details =

== Lex ==
First we will begin with Lex, Lex generates a C function called *Lexer* wich receives a stream of characters and recognizes some group of characters called [http://pt.wikipedia.org/wiki/Token tokens] and do some action. This is also called lexical [http://en.wikipedia.org/wiki/Lexical_analysis analysis]

For example this file will generate a program that wait the tokens *start* and *stop* and do some action, otherwise will just echo what was typed.

{{{
/* Definition part */
%{
#include <stdio.h>
%}

/* Rules */
%%
stop printf("Stop command received\n");
start printf("Start command received\n");
%%

/* Code */
}}}

For compile it:

{{{
lex example1.l
cc lex.yy.c -o example1 -ll
}}}

Anything between {% and %} will be copied to the output C file, sections will be separated with %% , the Rules part will be used to define the token rules as [http://en.wikipedia.org/wiki/Regular_expression regular expressions]. The code section will be used to define the *main* routine if you leave it empty and compile it with -ll the default main will be created, otherwise the yacc code will be used.

The other example will use a regular expression to define some token:

{{{
/* Definition part */
%{
#include <stdio.h>
%}

/* Rules */
%%
[0-9]+   printf("NUMBER\n");
[a-zA-Z][a-zA-Z0-9]*   printf("WORD\n");
%%

/* Code */
}}}

For compile it:

{{{
lex example2.l
cc lex.yy.c -o example1 -ll
}}}

The Rules part defines 2 tokens *NUMBER* and *WORD*
  * *NUMBER:* Defines a sequence of 1 or more characters from 0 to 9
  * *WORD:* In the first part matches 1 and only 1 character from a to z or A to Z then the second part could be zero or more characters from a to z or A to Z or 0 to 9

This way, we’ve mimicked the behaviour of many programming languages which demand that a variable name *must* start with a letter, but can contain digits afterwards. In other words, *’temperature1’* is a valid name, but *’1temperature’* is not.

Now we're going to define a *tokenizer* for reading a file that looks like this...

{{{
logging {
category lame-servers { null; };
category cname { null; };
};
zone "." {
type hint;
file "/etc/bind/db.root";
};
}}}

Just analysing this file we can see the following tokens
  * WORDs, like ’zone’ and ’type’
  * FILENAMEs, like ’/etc/bind/db.root’
  * QUOTEs, like those surrounding the filename
  * OBRACEs, {
  * EBRACEs, }
  * SEMICOLONs, ;

The lex file for *tokenizing* this file will be:

{{{
/* Definition part */
%{
#include <stdio.h>
%}

/* Rules */
%%
[a-zA-Z][a-zA-Z0-9]* printf("WORD ");
[a-zA-Z0-9\/.-]+ printf("FILENAME ");
\" printf("QUOTE ");
\{ printf("OBRACE ");
\} printf("EBRACE ");
; printf("SEMICOLON ");
\n printf("\n");
[ \t]+ /* ignore whitespace */;
%%

/* Code */
}}}

The output of this tokenizer will be:

{{{
WORD OBRACE
WORD FILENAME OBRACE WORD SEMICOLON EBRACE SEMICOLON
WORD WORD OBRACE WORD SEMICOLON EBRACE SEMICOLON
EBRACE SEMICOLON
WORD QUOTE FILENAME QUOTE OBRACE
WORD WORD SEMICOLON
WORD QUOTE FILENAME QUOTE SEMICOLON
EBRACE SEMICOLON
}}}

We’ve seen that Lex is able to read arbitrary input, and determine what each part of the input is. This is called ’Tokenizing’.
Now those tokens will be the input for *YACC* 

== YACC ==
YACC can [http://en.wikipedia.org/wiki/Parsing parse] input streams consisting of tokens witch certain values